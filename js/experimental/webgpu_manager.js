/**
 * ============================================================================
 * TaijiFlow AI - WebGPU Manager (Experimental Prototype)
 * ============================================================================
 *
 * à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸šà¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ WebGPU (Next-Gen Graphics API)
 * à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢: à¹à¸ªà¸”à¸‡à¸œà¸¥à¸§à¸´à¸”à¸µà¹‚à¸­à¸œà¹ˆà¸²à¸™ WebGPU Pipeline à¹€à¸žà¸·à¹ˆà¸­à¸§à¸±à¸”à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¹„à¸›à¹„à¸”à¹‰
 *
 * à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”:
 * - à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Browser à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š (Chrome 113+, Edge)
 * - Safari à¸•à¹‰à¸­à¸‡à¹€à¸›à¸´à¸” Feature Flag
 *
 * @version 0.1 (Prototype)
 */

class WebGPUManager {
  constructor() {
    this.adapter = null;
    this.device = null;
    this.context = null;
    this.pipeline = null;
    this.sampler = null;
    this.videoTexture = null;
    this.bindGroup = null;

    this.initialized = false;
    this.isSupported = false;
    this.width = 0;
    this.height = 0;
  }

  /**
   * à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸£à¸°à¸šà¸š WebGPU
   * @param {HTMLCanvasElement} canvas - Canvas à¸—à¸µà¹ˆà¸ˆà¸°à¸§à¸²à¸”
   */
  async init(canvas) {
    if (this.initialized) return this.isSupported;

    console.log("ðŸš€ WebGPU: Initializing Prototype...");

    // 1. Check Support
    if (!navigator.gpu) {
      console.warn("âŒ WebGPU not supported in this browser.");
      return false;
    }

    try {
      // 2. Request Adapter (GPU)
      this.adapter = await navigator.gpu.requestAdapter();
      if (!this.adapter) {
        console.error("âŒ No WebGPU adapter found.");
        return false;
      }

      // 3. Request Device
      this.device = await this.adapter.requestDevice();
      console.log(
        `âœ… WebGPU Device: ${this.adapter.limits.maxTextureDimension2D}px max texture`,
      );

      // 4. Configure Context
      this.context = canvas.getContext("webgpu");
      this.width = canvas.width;
      this.height = canvas.height;
      const format = navigator.gpu.getPreferredCanvasFormat(); // e.g. 'bgra8unorm'

      this.context.configure({
        device: this.device,
        format: format,
        alphaMode: "premultiplied",
      });

      // 5. Setup Shaders & Pipeline
      await this.setupPipeline(format);

      this.initialized = true;
      this.isSupported = true;
      console.log("âœ… WebGPU Initialized Successfully!");
      return true;
    } catch (e) {
      console.error("âŒ WebGPU Init Error:", e);
      return false;
    }
  }

  async setupPipeline(presentationFormat) {
    // --- WGSL Shaders ---
    const shaderModule = this.device.createShaderModule({
      label: "Video Passthrough Shader",
      code: `
        struct VertexOutput {
          @builtin(position) position : vec4f,
          @location(0) uv : vec2f,
        };

        // Fullscreen Quad Vertex Shader
        @vertex
        fn vs_main(@builtin(vertex_index) vertexIndex : u32) -> VertexOutput {
          var pos = array<vec2f, 6>(
            vec2f(-1.0, -1.0), vec2f( 1.0, -1.0), vec2f(-1.0,  1.0),
            vec2f(-1.0,  1.0), vec2f( 1.0, -1.0), vec2f( 1.0,  1.0)
          );

          var output : VertexOutput;
          let xy = pos[vertexIndex];
          output.position = vec4f(xy, 0.0, 1.0);
          
          // Map -1..1 to 0..1 and Flip Y for Texture
          output.uv = vec2f((xy.x + 1.0) * 0.5, 1.0 - (xy.y + 1.0) * 0.5);
          return output;
        }

        @group(0) @binding(0) var mySampler : sampler;
        @group(0) @binding(1) var myTexture : texture_external; // Use texture_external for Video

        @fragment
        fn fs_main(@location(0) uv : vec2f) -> @location(0) vec4f {
          return textureSampleBaseClampToEdge(myTexture, mySampler, uv);
        }
      `,
    });

    // --- Pipeline ---
    this.pipeline = this.device.createRenderPipeline({
      label: "Video Pipeline",
      layout: "auto",
      vertex: {
        module: shaderModule,
        entryPoint: "vs_main",
      },
      fragment: {
        module: shaderModule,
        entryPoint: "fs_main",
        targets: [{ format: presentationFormat }],
      },
      primitive: {
        topology: "triangle-list",
      },
    });

    // --- Sampler ---
    this.sampler = this.device.createSampler({
      magFilter: "linear",
      minFilter: "linear",
    });
  }

  /**
   * Render loop
   * @param {HTMLVideoElement} videoElement
   */
  render(videoElement) {
    if (!this.isSupported || !videoElement || videoElement.readyState < 2)
      return;

    // 1. Create Texture from Video (Zero-copy technique if supported)
    // importExternalTexture is highly efficient
    const externalTexture = this.device.importExternalTexture({
      source: videoElement,
    });

    // 2. Create BindGroup (Resources)
    // In optimized app, we cache this. But importExternalTexture returns new obj each frame.
    const bindGroup = this.device.createBindGroup({
      layout: this.pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: this.sampler },
        { binding: 1, resource: externalTexture }, // WGSL texture_external
      ],
    });

    // 3. Command Encoder
    const commandEncoder = this.device.createCommandEncoder();
    const textureView = this.context.getCurrentTexture().createView();

    const passEncoder = commandEncoder.beginRenderPass({
      colorAttachments: [
        {
          view: textureView,
          clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
          loadOp: "clear",
          storeOp: "store",
        },
      ],
    });

    passEncoder.setPipeline(this.pipeline);
    passEncoder.setBindGroup(0, bindGroup);
    passEncoder.draw(6); // Draw 6 vertices (Quad)
    passEncoder.end();

    // 4. Submit
    this.device.queue.submit([commandEncoder.finish()]);
  }
}
